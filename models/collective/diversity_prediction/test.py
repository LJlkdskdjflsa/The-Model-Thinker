#!/usr/bin/env python3
"""
å¤šæ¨£æ€§é æ¸¬å®šç†æ¸¬è©¦å¥—ä»¶
Diversity Prediction Theorem - Test Suite

å…¨é¢çš„å–®å…ƒæ¸¬è©¦å’Œé›†æˆæ¸¬è©¦

Author: Claude Code Assistant
License: MIT
"""

import unittest
import math
import sys
import os

# æ·»åŠ ç•¶å‰ç›®éŒ„åˆ°è·¯å¾‘ï¼Œä»¥ä¾¿å°å…¥æ¨¡å¡Š
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from diversity_simple import DiversityPredictionSimple

try:
    from diversity_prediction import DiversityPredictionTheorem
    FULL_VERSION_AVAILABLE = True
except ImportError:
    FULL_VERSION_AVAILABLE = False


class TestDiversityPredictionSimple(unittest.TestCase):
    """æ¸¬è©¦ DiversityPredictionSimple é¡çš„åŠŸèƒ½"""

    def setUp(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.theorem = DiversityPredictionSimple()

    def test_collective_error_basic(self):
        """æ¸¬è©¦é›†é«”èª¤å·®è¨ˆç®—"""
        predictions = [2, 8]
        true_value = 4
        expected = 1.0  # (5-4)Â² = 1

        result = self.theorem.collective_error(predictions, true_value)
        self.assertAlmostEqual(result, expected, places=6)

    def test_collective_error_perfect_prediction(self):
        """æ¸¬è©¦å®Œç¾é æ¸¬çš„é›†é«”èª¤å·®"""
        predictions = [10, 10, 10]
        true_value = 10
        expected = 0.0

        result = self.theorem.collective_error(predictions, true_value)
        self.assertAlmostEqual(result, expected, places=6)

    def test_average_individual_error_basic(self):
        """æ¸¬è©¦å¹³å‡å€‹é«”èª¤å·®è¨ˆç®—"""
        predictions = [2, 8]
        true_value = 4
        # å€‹é«”èª¤å·®: (2-4)Â² = 4, (8-4)Â² = 16
        # å¹³å‡: (4+16)/2 = 10
        expected = 10.0

        result = self.theorem.average_individual_error(predictions, true_value)
        self.assertAlmostEqual(result, expected, places=6)

    def test_prediction_diversity_basic(self):
        """æ¸¬è©¦é æ¸¬å¤šæ¨£æ€§è¨ˆç®—"""
        predictions = [2, 8]
        # å¹³å‡é æ¸¬: 5
        # å¤šæ¨£æ€§: ((2-5)Â² + (8-5)Â²)/2 = (9+9)/2 = 9
        expected = 9.0

        result = self.theorem.prediction_diversity(predictions)
        self.assertAlmostEqual(result, expected, places=6)

    def test_prediction_diversity_no_diversity(self):
        """æ¸¬è©¦ç„¡å¤šæ¨£æ€§æƒ…æ³"""
        predictions = [5, 5, 5]
        expected = 0.0

        result = self.theorem.prediction_diversity(predictions)
        self.assertAlmostEqual(result, expected, places=6)

    def test_verify_theorem_basic(self):
        """æ¸¬è©¦åŸºæœ¬å®šç†é©—è­‰"""
        predictions = [2, 8]
        true_value = 4

        result = self.theorem.verify_theorem(predictions, true_value)

        # æª¢æŸ¥å®šç†æ†ç­‰å¼
        self.assertTrue(result['theorem_holds'])
        self.assertAlmostEqual(result['difference'], 0.0, places=10)

        # æª¢æŸ¥å„é …è¨ˆç®—
        self.assertAlmostEqual(result['collective_error'], 1.0, places=6)
        self.assertAlmostEqual(result['average_individual_error'], 10.0, places=6)
        self.assertAlmostEqual(result['prediction_diversity'], 9.0, places=6)

    def test_verify_theorem_multiple_models(self):
        """æ¸¬è©¦å¤šæ¨¡å‹å®šç†é©—è­‰"""
        predictions = [10, 15, 20, 25]
        true_value = 18

        result = self.theorem.verify_theorem(predictions, true_value)

        # å®šç†æ‡‰è©²å§‹çµ‚æˆç«‹
        self.assertTrue(result['theorem_holds'])
        self.assertLess(result['difference'], 1e-10)

        # æª¢æŸ¥åŸºæœ¬å±¬æ€§
        self.assertGreaterEqual(result['prediction_diversity'], 0)
        self.assertGreaterEqual(result['average_individual_error'], 0)
        self.assertGreaterEqual(result['collective_error'], 0)

    def test_empty_predictions_error(self):
        """æ¸¬è©¦ç©ºé æ¸¬åˆ—è¡¨çš„éŒ¯èª¤è™•ç†"""
        with self.assertRaises(ValueError):
            self.theorem.collective_error([], 5)

        with self.assertRaises(ValueError):
            self.theorem.average_individual_error([], 5)

        with self.assertRaises(ValueError):
            self.theorem.prediction_diversity([])

    def test_single_prediction(self):
        """æ¸¬è©¦å–®å€‹é æ¸¬çš„æƒ…æ³"""
        predictions = [7]
        true_value = 5

        collective_error = self.theorem.collective_error(predictions, true_value)
        avg_individual_error = self.theorem.average_individual_error(predictions, true_value)
        diversity = self.theorem.prediction_diversity(predictions)

        # å–®å€‹é æ¸¬æ™‚ï¼Œé›†é«”èª¤å·®ç­‰æ–¼å€‹é«”èª¤å·®
        self.assertAlmostEqual(collective_error, avg_individual_error, places=6)
        # å–®å€‹é æ¸¬æ™‚ï¼Œå¤šæ¨£æ€§ç‚º0
        self.assertAlmostEqual(diversity, 0.0, places=6)

    def test_analyze_diversity_impact(self):
        """æ¸¬è©¦å¤šæ¨£æ€§å½±éŸ¿åˆ†æ"""
        predictions = [10, 20, 30]
        true_value = 25

        analysis = self.theorem.analyze_diversity_impact(predictions, true_value)

        # æª¢æŸ¥è¿”å›çµæ§‹
        self.assertIn('basic_metrics', analysis)
        self.assertIn('diversity_benefit', analysis)
        self.assertIn('improvement_ratio', analysis)
        self.assertIn('quality_assessment', analysis)

        # æª¢æŸ¥æ”¹å–„æ¯”ä¾‹åˆç†æ€§
        self.assertGreaterEqual(analysis['improvement_ratio'], 0)
        self.assertLessEqual(analysis['improvement_ratio'], 1)

    def test_compare_scenarios(self):
        """æ¸¬è©¦å ´æ™¯æ¯”è¼ƒåŠŸèƒ½"""
        scenarios = [
            ([10, 10, 10], 10, "ç„¡å¤šæ¨£æ€§"),
            ([5, 10, 15], 10, "ä¸­ç­‰å¤šæ¨£æ€§"),
            ([0, 10, 20], 10, "é«˜å¤šæ¨£æ€§")
        ]

        comparison = self.theorem.compare_scenarios(scenarios)

        # æª¢æŸ¥è¿”å›çµæ§‹
        self.assertIn('scenarios', comparison)
        self.assertIn('best_scenario', comparison)
        self.assertIn('best_error', comparison)

        # æª¢æŸ¥å ´æ™¯æ•¸é‡
        self.assertEqual(len(comparison['scenarios']), 3)

        # æœ€ä½³å ´æ™¯æ‡‰è©²æ˜¯èª¤å·®æœ€å°çš„
        best_name = comparison['best_scenario']
        best_error = comparison['best_error']
        self.assertEqual(best_error, comparison['scenarios'][best_name]['collective_error'])

    def test_generate_diversity_examples(self):
        """æ¸¬è©¦ç¯„ä¾‹ç”ŸæˆåŠŸèƒ½"""
        examples = self.theorem.generate_diversity_examples()

        # æª¢æŸ¥ç¯„ä¾‹æ•¸é‡å’Œçµæ§‹
        self.assertGreater(len(examples), 0)

        for example in examples:
            self.assertIn('name', example)
            self.assertIn('predictions', example)
            self.assertIn('true_value', example)
            self.assertIn('results', example)

            # é©—è­‰æ¯å€‹ç¯„ä¾‹çš„å®šç†
            self.assertTrue(example['results']['theorem_holds'])

    def test_simulate_bias_effect(self):
        """æ¸¬è©¦åå·®æ•ˆæ‡‰æ¨¡æ“¬"""
        base_predictions = [8, 10, 12]
        true_value = 10
        bias = 3

        bias_analysis = self.theorem.simulate_bias_effect(base_predictions, true_value, bias)

        # æª¢æŸ¥è¿”å›çµæ§‹
        self.assertIn('unbiased_results', bias_analysis)
        self.assertIn('biased_results', bias_analysis)
        self.assertIn('bias_impact', bias_analysis)

        # æª¢æŸ¥åå·®ä¸æ”¹è®Šå¤šæ¨£æ€§
        self.assertTrue(bias_analysis['bias_impact']['diversity_unchanged'])

        # æª¢æŸ¥åå·®å°é›†é«”èª¤å·®çš„å½±éŸ¿
        bias_impact = bias_analysis['bias_impact']['collective_error_change']
        self.assertGreater(bias_impact, 0)  # åå·®æ‡‰è©²å¢åŠ èª¤å·®

    def test_mathematical_properties(self):
        """æ¸¬è©¦æ•¸å­¸æ€§è³ª"""
        # æ¸¬è©¦ä¸åŒçš„é æ¸¬çµ„åˆ
        test_cases = [
            ([1, 2, 3], 2),
            ([0, 5, 10], 5),
            ([-5, 0, 5], 0),
            ([100, 200, 300], 200),
            ([0.1, 0.2, 0.3], 0.2)
        ]

        for predictions, true_value in test_cases:
            with self.subTest(predictions=predictions, true_value=true_value):
                result = self.theorem.verify_theorem(predictions, true_value)

                # å®šç†æ‡‰è©²å§‹çµ‚æˆç«‹
                self.assertTrue(result['theorem_holds'])

                # å¤šæ¨£æ€§æ‡‰è©²éè² 
                self.assertGreaterEqual(result['prediction_diversity'], 0)

                # èª¤å·®æ‡‰è©²éè² 
                self.assertGreaterEqual(result['collective_error'], 0)
                self.assertGreaterEqual(result['average_individual_error'], 0)


class TestDiversityPredictionAdvanced(unittest.TestCase):
    """æ¸¬è©¦é€²éšåŠŸèƒ½ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""

    def setUp(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        if FULL_VERSION_AVAILABLE:
            self.theorem = DiversityPredictionTheorem(enable_visualization=False)
        else:
            self.skipTest("å®Œæ•´ç‰ˆæœ¬ä¸å¯ç”¨")

    def test_ensemble_analysis(self):
        """æ¸¬è©¦é›†æˆåˆ†æåŠŸèƒ½"""
        if not FULL_VERSION_AVAILABLE:
            self.skipTest("å®Œæ•´ç‰ˆæœ¬ä¸å¯ç”¨")

        models_data = [
            {'name': 'æ¨¡å‹A', 'predictions': [10, 20, 30]},
            {'name': 'æ¨¡å‹B', 'predictions': [12, 18, 32]},
            {'name': 'æ¨¡å‹C', 'predictions': [8, 22, 28]}
        ]
        true_values = [10, 20, 30]

        analysis = self.theorem.ensemble_analysis(models_data, true_values)

        # æª¢æŸ¥è¿”å›çµæ§‹
        self.assertIn('ensemble_metrics', analysis)
        self.assertIn('sample_analyses', analysis)
        self.assertIn('model_performances', analysis)

        # æª¢æŸ¥æ¨£æœ¬åˆ†ææ•¸é‡
        self.assertEqual(len(analysis['sample_analyses']), len(true_values))

        # æª¢æŸ¥æ¨¡å‹è¡¨ç¾åˆ†æ
        self.assertEqual(len(analysis['model_performances']), len(models_data))

    def test_diversity_vs_accuracy_study(self):
        """æ¸¬è©¦å¤šæ¨£æ€§èˆ‡æº–ç¢ºæ€§é—œä¿‚ç ”ç©¶"""
        if not FULL_VERSION_AVAILABLE:
            self.skipTest("å®Œæ•´ç‰ˆæœ¬ä¸å¯ç”¨")

        study_results = self.theorem.diversity_vs_accuracy_study(
            min_models=2, max_models=4, diversity_levels=[0.2, 0.5, 0.8]
        )

        # æª¢æŸ¥è¿”å›çµæ§‹
        self.assertIn('study_results', study_results)
        self.assertIn('diversity_levels', study_results)
        self.assertIn('model_range', study_results)

        # æª¢æŸ¥çµæœæ•¸é‡
        expected_count = (4-2+1) * 3  # 3 models * 3 diversity levels
        self.assertEqual(len(study_results['study_results']), expected_count)

    def test_generate_comprehensive_report(self):
        """æ¸¬è©¦ç¶œåˆå ±å‘Šç”Ÿæˆ"""
        if not FULL_VERSION_AVAILABLE:
            self.skipTest("å®Œæ•´ç‰ˆæœ¬ä¸å¯ç”¨")

        predictions = [85, 90, 95]
        true_value = 88

        report = self.theorem.generate_comprehensive_report(predictions, true_value)

        # æª¢æŸ¥å ±å‘ŠåŒ…å«é—œéµä¿¡æ¯
        self.assertIn("å¤šæ¨£æ€§é æ¸¬å®šç†åˆ†æå ±å‘Š", report)
        self.assertIn("åŸºæœ¬ä¿¡æ¯", report)
        self.assertIn("æ ¸å¿ƒæŒ‡æ¨™", report)
        self.assertIn("å®šç†é©—è­‰", report)
        self.assertIn("çµè«–", report)


class TestTheoremMathematicalProperties(unittest.TestCase):
    """æ¸¬è©¦å®šç†çš„æ•¸å­¸æ€§è³ª"""

    def setUp(self):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        self.theorem = DiversityPredictionSimple()

    def test_theorem_identity_property(self):
        """æ¸¬è©¦å®šç†æ†ç­‰å¼æ€§è³ª"""
        # ä½¿ç”¨å¤šç¨®ä¸åŒçš„é æ¸¬çµ„åˆ
        test_cases = [
            ([1], 1),           # å–®å€‹æº–ç¢ºé æ¸¬
            ([1], 2),           # å–®å€‹ä¸æº–ç¢ºé æ¸¬
            ([1, 1], 1),        # å…©å€‹ç›¸åŒçš„æº–ç¢ºé æ¸¬
            ([1, 3], 2),        # å…©å€‹å°ç¨±é æ¸¬
            ([1, 2, 3], 2),     # ä¸‰å€‹ç­‰å·®é æ¸¬
            ([0, 10], 3),       # å¤§ç¯„åœé æ¸¬
            ([-5, 5], 0),       # åŒ…å«è² æ•¸çš„é æ¸¬
            ([1.1, 1.2, 1.3], 1.2),  # å°æ•¸é æ¸¬
        ]

        for predictions, true_value in test_cases:
            with self.subTest(predictions=predictions, true_value=true_value):
                collective = self.theorem.collective_error(predictions, true_value)
                avg_individual = self.theorem.average_individual_error(predictions, true_value)
                diversity = self.theorem.prediction_diversity(predictions)

                # é©—è­‰æ†ç­‰å¼ï¼šé›†é«”èª¤å·® = å¹³å‡å€‹é«”èª¤å·® - é æ¸¬å¤šæ¨£æ€§
                left_side = collective
                right_side = avg_individual - diversity

                self.assertAlmostEqual(left_side, right_side, places=10,
                                     msg=f"å®šç†ä¸æˆç«‹: {predictions}, {true_value}")

    def test_diversity_non_negative(self):
        """æ¸¬è©¦å¤šæ¨£æ€§éè² æ€§"""
        test_predictions = [
            [1, 2, 3],
            [0, 0, 0],
            [-1, 0, 1],
            [100, 200, 300],
            [0.1, 0.1, 0.1]
        ]

        for predictions in test_predictions:
            with self.subTest(predictions=predictions):
                diversity = self.theorem.prediction_diversity(predictions)
                self.assertGreaterEqual(diversity, 0,
                                      msg=f"å¤šæ¨£æ€§ç‚ºè² : {predictions}")

    def test_diversity_zero_iff_identical(self):
        """æ¸¬è©¦å¤šæ¨£æ€§ç‚ºé›¶ç•¶ä¸”åƒ…ç•¶æ‰€æœ‰é æ¸¬ç›¸åŒ"""
        # å¤šæ¨£æ€§ç‚ºé›¶çš„æƒ…æ³
        identical_cases = [
            [5, 5, 5],
            [0, 0, 0],
            [-3, -3, -3],
            [1.5, 1.5, 1.5]
        ]

        for predictions in identical_cases:
            with self.subTest(predictions=predictions, case="identical"):
                diversity = self.theorem.prediction_diversity(predictions)
                self.assertAlmostEqual(diversity, 0, places=10)

        # å¤šæ¨£æ€§å¤§æ–¼é›¶çš„æƒ…æ³
        diverse_cases = [
            [1, 2],
            [0, 1, 2],
            [-1, 0, 1],
            [1.0, 1.1]
        ]

        for predictions in diverse_cases:
            with self.subTest(predictions=predictions, case="diverse"):
                diversity = self.theorem.prediction_diversity(predictions)
                self.assertGreater(diversity, 0)

    def test_collective_error_properties(self):
        """æ¸¬è©¦é›†é«”èª¤å·®çš„æ€§è³ª"""
        true_value = 10

        # æ¸¬è©¦1: å®Œç¾å¹³å‡é æ¸¬
        perfect_avg_predictions = [9, 10, 11]  # å¹³å‡=10
        collective_error = self.theorem.collective_error(perfect_avg_predictions, true_value)
        self.assertAlmostEqual(collective_error, 0, places=10)

        # æ¸¬è©¦2: é›†é«”èª¤å·®èˆ‡å€‹é«”æ•¸é‡ç„¡é—œï¼ˆå°æ–¼ç›¸åŒå¹³å‡å€¼ï¼‰
        predictions_3 = [8, 10, 12]  # å¹³å‡=10
        predictions_5 = [6, 8, 10, 12, 14]  # å¹³å‡=10

        error_3 = self.theorem.collective_error(predictions_3, true_value)
        error_5 = self.theorem.collective_error(predictions_5, true_value)

        self.assertAlmostEqual(error_3, error_5, places=10)

    def test_symmetry_properties(self):
        """æ¸¬è©¦å°ç¨±æ€§æ€§è³ª"""
        true_value = 10

        # å°ç¨±é æ¸¬æ‡‰è©²ç”¢ç”Ÿç›¸åŒçš„å¤šæ¨£æ€§
        symmetric_cases = [
            ([8, 12], [12, 8]),  # é †åºå°ç¨±
            ([5, 10, 15], [15, 10, 5]),  # é †åºå°ç¨±
            ([7, 10, 13], [13, 10, 7])   # é †åºå°ç¨±
        ]

        for pred1, pred2 in symmetric_cases:
            with self.subTest(pred1=pred1, pred2=pred2):
                diversity1 = self.theorem.prediction_diversity(pred1)
                diversity2 = self.theorem.prediction_diversity(pred2)
                self.assertAlmostEqual(diversity1, diversity2, places=10)

                # é›†é«”èª¤å·®ä¹Ÿæ‡‰è©²ç›¸åŒ
                error1 = self.theorem.collective_error(pred1, true_value)
                error2 = self.theorem.collective_error(pred2, true_value)
                self.assertAlmostEqual(error1, error2, places=10)

    def test_scaling_properties(self):
        """æ¸¬è©¦ç¸®æ”¾æ€§è³ª"""
        base_predictions = [8, 10, 12]
        base_true_value = 10
        scale_factor = 2.5

        # ç¸®æ”¾é æ¸¬å’ŒçœŸå¯¦å€¼
        scaled_predictions = [p * scale_factor for p in base_predictions]
        scaled_true_value = base_true_value * scale_factor

        # è¨ˆç®—åŸå§‹å’Œç¸®æ”¾å¾Œçš„çµæœ
        base_result = self.theorem.verify_theorem(base_predictions, base_true_value)
        scaled_result = self.theorem.verify_theorem(scaled_predictions, scaled_true_value)

        # èª¤å·®æ‡‰è©²æŒ‰æ¯”ä¾‹ç¸®æ”¾ï¼ˆå¹³æ–¹é—œä¿‚ï¼‰
        scale_factor_squared = scale_factor ** 2

        self.assertAlmostEqual(
            scaled_result['collective_error'],
            base_result['collective_error'] * scale_factor_squared,
            places=8
        )

        self.assertAlmostEqual(
            scaled_result['prediction_diversity'],
            base_result['prediction_diversity'] * scale_factor_squared,
            places=8
        )


def run_performance_tests():
    """é‹è¡Œæ€§èƒ½æ¸¬è©¦"""
    import time

    print("\n" + "="*50)
    print("ğŸš€ æ€§èƒ½æ¸¬è©¦")
    print("="*50)

    theorem = DiversityPredictionSimple()

    # æ¸¬è©¦å¤§é‡æ¨¡å‹çš„æ€§èƒ½
    model_counts = [10, 50, 100, 500, 1000]

    for n_models in model_counts:
        # ç”Ÿæˆæ¸¬è©¦æ•¸æ“š
        predictions = list(range(n_models))
        true_value = n_models // 2

        # æ¸¬é‡åŸ·è¡Œæ™‚é–“
        start_time = time.time()
        result = theorem.verify_theorem(predictions, true_value)
        end_time = time.time()

        elapsed = (end_time - start_time) * 1000  # è½‰æ›ç‚ºæ¯«ç§’

        print(f"{n_models:4d} æ¨¡å‹: {elapsed:6.2f}ms, å®šç†æˆç«‹: {result['theorem_holds']}")

    print("\nâœ… æ€§èƒ½æ¸¬è©¦å®Œæˆ")


def run_edge_case_tests():
    """é‹è¡Œé‚Šç·£æƒ…æ³æ¸¬è©¦"""
    print("\n" + "="*50)
    print("ğŸ§ª é‚Šç·£æƒ…æ³æ¸¬è©¦")
    print("="*50)

    theorem = DiversityPredictionSimple()

    # æ¥µç«¯å€¼æ¸¬è©¦
    edge_cases = [
        ("æ¥µå¤§å€¼", [1e6, 1e6+1, 1e6+2], 1e6+1),
        ("æ¥µå°å€¼", [1e-6, 2e-6, 3e-6], 2e-6),
        ("é›¶å€¼", [0, 0, 0], 0),
        ("è² å€¼", [-10, -5, 0], -5),
        ("æ··åˆç¬¦è™Ÿ", [-10, 0, 10], 0),
    ]

    for name, predictions, true_value in edge_cases:
        try:
            result = theorem.verify_theorem(predictions, true_value)
            status = "âœ… é€šé" if result['theorem_holds'] else "âŒ å¤±æ•—"
            print(f"{name:<12}: {status}, èª¤å·®å·®ç•°: {result['difference']:.2e}")
        except Exception as e:
            print(f"{name:<12}: âŒ éŒ¯èª¤ - {e}")

    print("\nâœ… é‚Šç·£æƒ…æ³æ¸¬è©¦å®Œæˆ")


def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª å¤šæ¨£æ€§é æ¸¬å®šç†æ¸¬è©¦å¥—ä»¶")
    print("="*60)

    # é‹è¡Œå–®å…ƒæ¸¬è©¦
    print("\nğŸ“‹ é‹è¡Œå–®å…ƒæ¸¬è©¦...")

    # å‰µå»ºæ¸¬è©¦å¥—ä»¶
    test_suite = unittest.TestSuite()

    # æ·»åŠ æ¸¬è©¦é¡
    test_classes = [
        TestDiversityPredictionSimple,
        TestDiversityPredictionAdvanced,
        TestTheoremMathematicalProperties
    ]

    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)

    # é‹è¡Œæ¸¬è©¦
    runner = unittest.TextTestRunner(verbosity=2)
    test_result = runner.run(test_suite)

    # é‹è¡Œé¡å¤–æ¸¬è©¦
    run_performance_tests()
    run_edge_case_tests()

    # ç¸½çµ
    print("\n" + "="*60)
    print("ğŸ“Š æ¸¬è©¦ç¸½çµ")
    print("="*60)

    total_tests = test_result.testsRun
    failures = len(test_result.failures)
    errors = len(test_result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests * 100) if total_tests > 0 else 0

    print(f"ç¸½æ¸¬è©¦æ•¸: {total_tests}")
    print(f"æˆåŠŸ: {total_tests - failures - errors}")
    print(f"å¤±æ•—: {failures}")
    print(f"éŒ¯èª¤: {errors}")
    print(f"æˆåŠŸç‡: {success_rate:.1f}%")

    if failures == 0 and errors == 0:
        print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼")
        return 0
    else:
        print("\nâš ï¸ éƒ¨åˆ†æ¸¬è©¦å¤±æ•—ï¼Œè«‹æª¢æŸ¥ä»£ç¢¼")
        return 1


if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)